{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part 2 of the assignment, we switch from text processing to image processing to explore\n",
    "another set of model tasks. Again, you are asked to follow a set of instructions below and report\n",
    "on your findings.\n",
    "For this assignment we will make use of the CIFAR-100 dataset of images. Rather than using all\n",
    "images, you are asked to randomly split CIFAR into two subsets of 50 classes each. Your first\n",
    "task is to make these subsets and save these subsets to disk for use later. Make sure to randomly\n",
    "select these classes (donâ€™t just take the first 50). Also make sure to account for training, validation,\n",
    "or test as appropriate. We will refer to the first set of data as Block 1 and the second set of 50\n",
    "classes as Block 2.\n",
    "As with Part 1, the set of tasks below do not build on each other and can in some ways be\n",
    "considered independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_epochs = 50\n",
    "num_classes = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# Randomly select 50 classes for Block 1\n",
    "np.random.seed(42)  # For reproducibility\n",
    "class_indices = np.random.choice(range(100), 50, replace=False)\n",
    "\n",
    "# Find indices for Block 1 (train data)\n",
    "block1_train_indices = np.where(np.isin(y_train, class_indices))[0]\n",
    "block2_train_indices = np.where(~np.isin(y_train, class_indices))[0]\n",
    "\n",
    "# Find indices for Block 1 (test data)\n",
    "block1_test_indices = np.where(np.isin(y_test, class_indices))[0]\n",
    "block2_test_indices = np.where(~np.isin(y_test, class_indices))[0]\n",
    "\n",
    "# Prepare Block 1 and Block 2 datasets\n",
    "x_train_block1, y_train_block1 = x_train[block1_train_indices], y_train[block1_train_indices]\n",
    "x_train_block2, y_train_block2 = x_train[block2_train_indices], y_train[block2_train_indices]\n",
    "x_test_block1, y_test_block1 = x_test[block1_test_indices], y_test[block1_test_indices]\n",
    "x_test_block2, y_test_block2 = x_test[block2_test_indices], y_test[block2_test_indices]\n",
    "\n",
    "# Split Block 1's training data into training and validation sets (80% train, 20% validation)\n",
    "x_train_block1, x_val_block1, y_train_block1, y_val_block1 = train_test_split(\n",
    "    x_train_block1, y_train_block1, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split Block 2's training data into training and validation sets (80% train, 20% validation)\n",
    "x_train_block2, x_val_block2, y_train_block2, y_val_block2 = train_test_split(\n",
    "    x_train_block2, y_train_block2, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Remap labels for Block 1 to be in the range [0, 49]\n",
    "class_to_new_label = {old_class: new_class for new_class, old_class in enumerate(class_indices)}\n",
    "y_train_block1 = np.vectorize(class_to_new_label.get)(y_train_block1)\n",
    "y_val_block1 = np.vectorize(class_to_new_label.get)(y_val_block1)\n",
    "y_test_block1 = np.vectorize(class_to_new_label.get)(y_test_block1)\n",
    "\n",
    "y_train_block2 = np.vectorize(class_to_new_label.get)(y_train_block2)\n",
    "y_val_block2 = np.vectorize(class_to_new_label.get)(y_val_block2)\n",
    "y_test_block2 = np.vectorize(class_to_new_label.get)(y_test_block2)\n",
    "\n",
    "y_train_block1_one_hot = to_categorical(y_train_block1, num_classes=num_classes)\n",
    "y_val_block1_one_hot = to_categorical(y_val_block1, num_classes=num_classes)\n",
    "y_test_block1_one_hot = to_categorical(y_test_block1, num_classes=num_classes)\n",
    "\n",
    "# Save data as .npz files\n",
    "np.savez('block1_data.npz', x_train=x_train_block1, y_train=y_train_block1, x_val=x_val_block1, y_val=y_val_block1, x_test=x_test_block1, y_test=y_test_block1)\n",
    "np.savez('block2_data.npz', x_train=x_train_block2, y_train=y_train_block2, x_val=x_val_block2, y_val=y_val_block2, x_test=x_test_block2, y_test=y_test_block2)\n",
    "\n",
    "# Check the shapes of the datasets\n",
    "print(f'Block 1 train shape: {x_train_block1.shape}, Block 1 val shape: {x_val_block1.shape}, Block 1 test shape: {x_test_block1.shape}')\n",
    "print(f'Block 2 train shape: {x_train_block2.shape}, Block 2 test shape: {x_test_block2.shape}')\n",
    "\n",
    "\n",
    "# Function to plot images\n",
    "def plot_images(images, labels, title):\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i in range(5):\n",
    "        ax = plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"Label: {labels[i][0]}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot 5 images from the training set\n",
    "plot_images(x_train, y_train, \"Training Set\")\n",
    "\n",
    "# Plot 5 images from the test set\n",
    "plot_images(x_test, y_test, \"Test Set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
